{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efee33b-c055-4441-b43b-a97e2232f23c",
   "metadata": {},
   "source": [
    "![](https://i.ytimg.com/vi/MKxEbbKpL5Q/maxresdefault.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d7fb2-8d4d-4cf5-8055-ef1ea91f899f",
   "metadata": {},
   "source": [
    "In this tutorial we builds an pipeline for training an pytorch model on real world dataset, Breast-Cancer-Detection. \n",
    "\n",
    "## Plan Of Attack \n",
    "\n",
    "- We will build a simple neural network\n",
    "- Train it on real world dataset\n",
    "- Will mimic the PyTorch worlflow\n",
    "- Will have a lot of manual elements\n",
    "- End result is not important\n",
    "\n",
    "## Code Flow \n",
    "- Load the dataset\n",
    "- Basic Preprocessing\n",
    "- Training Process\n",
    "  - Create the model\n",
    "  - Forward pass\n",
    "  - Loss calculation\n",
    "  - Backprop\n",
    "  - Parameter update\n",
    "- Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edb84a-2fe0-4a15-856d-724470ea2a81",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599adbee-f9e6-42d4-9ecb-4d76bb4ce0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d952f9-fe8c-4def-be89-cfcee2dd2d7f",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497e7266-b602-4d7a-9f25-3f5bfb8744bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst  Unnamed: 32\n",
       "0    842302         M        17.99  ...          0.4601                  0.11890          NaN\n",
       "1    842517         M        20.57  ...          0.2750                  0.08902          NaN\n",
       "2  84300903         M        19.69  ...          0.3613                  0.08758          NaN\n",
       "3  84348301         M        11.42  ...          0.6638                  0.17300          NaN\n",
       "4  84358402         M        20.29  ...          0.2364                  0.07678          NaN\n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa665f63-1bd4-4c10-a071-2ef869d3bfd4",
   "metadata": {},
   "source": [
    "## Check Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80edc810-71f0-4935-b829-da3e5b4e4d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace207c-7a70-41e2-9663-7b997a9b3032",
   "metadata": {},
   "source": [
    "## Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ac2708-d0c1-4d99-989c-6fe01bf4a720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d4dfb-e376-44a0-80f8-7ae15d5c38c5",
   "metadata": {},
   "source": [
    "## Check Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "874b6e69-f652-4c1c-888a-428fda0f7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c811b5-f5ab-4290-a9fc-bdc100c1d064",
   "metadata": {},
   "source": [
    "## Drop Un-Necessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d1844a-8860-49ef-b4e3-451fe41634dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','Unnamed: 32'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df438bf-dc30-4932-afe6-ff2d21add89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd172c21-44f4-4e86-b9f1-6d23680d40ab",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e73da1f-ce62-4a8a-92bc-8a5ac5d297a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77db30e-eed2-4f45-8307-7da051d53c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f97ac9-67c8-4f1e-ae29-074d2aeab5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c69cfc-80d4-4247-aaf7-6deeeabb8c12",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b3d3cd-0dbd-4ad1-92d1-78cbb180b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce2a7e-55d2-4a24-921e-1b3b7319cdbf",
   "metadata": {},
   "source": [
    "## Label Encoding Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c15fb30-7a89-4ca7-ae87-a9982ef701bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224    B\n",
       "252    M\n",
       "82     M\n",
       "88     B\n",
       "169    B\n",
       "      ..\n",
       "419    B\n",
       "120    B\n",
       "368    M\n",
       "48     B\n",
       "207    M\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413123fd-3388-4736-8690-f38bc2ddde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714de0bd-bdf8-4d89-b37f-8f4b91b0ea6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78223ea1-6f7e-48b4-8c7b-0d4dd7350168",
   "metadata": {},
   "source": [
    "## Numpy Arrays to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d4e9f2-3e67-439d-a8d4-91790bf320be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train_sc)\n",
    "X_test_tensor = torch.from_numpy(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ccb39e4-046b-40dd-9e73-3d5e2398595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "# print(y_train_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5f1394-dcde-45f7-bb89-f0023ba09eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2605, -0.5458, -0.3234,  ..., -0.3044, -0.6542, -0.4403],\n",
       "        [ 1.5758,  0.1002,  1.5788,  ...,  2.0245, -0.2604,  2.4445],\n",
       "        [ 3.1365,  1.2745,  3.2606,  ...,  2.5692, -0.8988,  1.1173],\n",
       "        ...,\n",
       "        [ 2.1387, -0.4928,  1.9993,  ...,  0.9850, -0.6477, -1.0494],\n",
       "        [-0.6073, -1.0972, -0.5918,  ..., -0.7780, -0.2637, -0.0745],\n",
       "        [ 0.8026,  0.2017,  0.7132,  ..., -0.1104,  0.5918, -1.0629]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92c125f-7371-43e9-8e51-e99fb5526dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9456,  0.4832, -0.9846,  ..., -1.7688, -0.7319, -0.9966],\n",
       "        [ 0.2170, -0.1421,  0.2244,  ..., -0.4970, -0.0935,  0.4202],\n",
       "        [ 1.7350, -1.1641,  1.7602,  ...,  0.6900, -0.8842, -0.4106],\n",
       "        ...,\n",
       "        [-0.6017, -1.3718, -0.6004,  ..., -0.6502, -0.2086, -0.2089],\n",
       "        [-1.5679, -1.1387, -1.5654,  ..., -1.7688, -0.5148, -0.3189],\n",
       "        [ 0.3620, -1.7294,  0.4164,  ...,  0.9956,  0.4962,  0.8961]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abca37-1650-4702-a35f-b9721776ead2",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b6985d6-82bc-4a70-8692-3338e55f5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self,X):\n",
    "        self.weights = torch.rand(X.shape[1],1,dtype=torch.float64,requires_grad=True)\n",
    "        self.bias = torch.zeros(1,dtype=torch.float64,requires_grad=True)\n",
    "\n",
    "    def forward(self,X):\n",
    "        z = torch.matmul(X,self.weights) + self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred \n",
    "\n",
    "    def loss_function(self,y_pred,y):\n",
    "        ## clamp prediction to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred,epsilon,1-epsilon)\n",
    "\n",
    "        # calculate loss \n",
    "        loss = - (y*torch.log(y_pred) + (1-y)*torch.log(1-y_pred)).mean()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7c7876-c4be-4f11-8e00-98626f46bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define learning rate and epochs \n",
    "learning_rate = 0.1\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55c86b49-7393-4bf7-b7aa-ad57dc57a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.7114025878065\n",
      "Epoch: 2, Loss: 3.5876286100427626\n",
      "Epoch: 3, Loss: 3.4598653337888807\n",
      "Epoch: 4, Loss: 3.3243590286831264\n",
      "Epoch: 5, Loss: 3.185792317436818\n",
      "Epoch: 6, Loss: 3.0433185554277813\n",
      "Epoch: 7, Loss: 2.8911685512162917\n",
      "Epoch: 8, Loss: 2.7367579244426925\n",
      "Epoch: 9, Loss: 2.5767485718670056\n",
      "Epoch: 10, Loss: 2.415778792810994\n",
      "Epoch: 11, Loss: 2.2525793394060436\n",
      "Epoch: 12, Loss: 2.0904321920999482\n",
      "Epoch: 13, Loss: 1.9342458756034022\n",
      "Epoch: 14, Loss: 1.7825303869036444\n",
      "Epoch: 15, Loss: 1.640246028053891\n",
      "Epoch: 16, Loss: 1.5049443491238101\n",
      "Epoch: 17, Loss: 1.372819006291432\n",
      "Epoch: 18, Loss: 1.2554214147485698\n",
      "Epoch: 19, Loss: 1.1541090436993995\n",
      "Epoch: 20, Loss: 1.0696149389169005\n",
      "Epoch: 21, Loss: 1.0015699741086674\n",
      "Epoch: 22, Loss: 0.948351604018355\n",
      "Epoch: 23, Loss: 0.9074400165131351\n",
      "Epoch: 24, Loss: 0.8760442243822558\n",
      "Epoch: 25, Loss: 0.8516319692893628\n"
     ]
    }
   ],
   "source": [
    "## create model\n",
    "\n",
    "model = MyModel(X_train_tensor)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## forward pass\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "    ## loss function\n",
    "    loss = model.loss_function(y_pred,y_train_tensor)\n",
    "    ## backward pass\n",
    "    loss.backward()\n",
    "    ## parameter update \n",
    "    with torch.no_grad():\n",
    "        model.weights -= learning_rate * model.weights.grad\n",
    "        model.bias -= learning_rate * model.bias.grad\n",
    "\n",
    "    ## zero gradient \n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "563712a9-8ca9-4cff-9569-46f91e885713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b25b7e1-805f-47ed-abb8-ce9488513a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1219], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da578a0d-de28-40d7-bf15-fb5e5fbfc0b3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62a648fd-a30d-4b0f-8ac5-574573d59fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.638504147529602\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred>0.9).float()\n",
    "    accuracy = (y_pred==y_test_tensor).float().mean()\n",
    "    print(f'Accuarcy: {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fc1ec-eef8-4a3c-b36d-a43953219a48",
   "metadata": {},
   "source": [
    "![](https://i.ytimg.com/vi/CAgWNxlmYsc/hqdefault.jpg)\n",
    "\n",
    "## Plan Of Action \n",
    "- The nn module\n",
    "- The torch.optim module\n",
    "- Improvement Existing Model\n",
    "\n",
    "## Improvements \n",
    "- Buiding Neural Network using nn module\n",
    "- Using built in activation function\n",
    "- Using built-in loss function\n",
    "- Using built-in optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5629e-d791-4548-bfc8-b7b340e4a716",
   "metadata": {},
   "source": [
    "# The nn module\n",
    "\n",
    "### **The torch.nn module in PyTorch is a core library that provides a wide array of classes and functions designed to help developers build neural networks efficiently and effectively.**\n",
    "### **It abstarcts the complexity of creating and training neural networks by offering pre-builts layers, loss functions, activations or other utilities, enabling you to focus on designing and experimenting with model architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fcee1-ee4f-4590-a359-94ad45fc733f",
   "metadata": {},
   "source": [
    "# Key Components of torch.nn\n",
    "\n",
    "1. Modules (Layers):\n",
    "   - **nn.module:** The base class for all neural network modules. Your custom models and layers subclass in this class.\n",
    "   - **Common Layers:** Includes layers like **nn.Liner (fully connected layer), nn.Conv2d (convolution layer), nn.LSTM (recurrent layer)** and many others.\n",
    "\n",
    "2. Actiavtion Functions\n",
    "   - Functions like **nn.ReLu**, **nn.Sigmoid**, **nn.Tanh** introduces non-linearility to the model, allowing it to learn complex patterns.\n",
    "\n",
    "3. Loss Functions:\n",
    "   - Provides Loss functions such as **nn.CrossEntropyLoss, nn.MSELoss, nn.NLLLoss** to quantify the difference between the model's predictions and the actual targets.\n",
    "\n",
    "4. Container Modules:\n",
    "   - **nn.Sequential:** A sequential container to stack layers in order.\n",
    "\n",
    "5. Regularization and Dropout:\n",
    "   - Layers like **nn.Dropout and nn.BatchNorm2d** help prevent overfitting and improve the model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c44db0-a37f-485e-9025-16bca73bbd80",
   "metadata": {},
   "source": [
    "## The torch.optim module \n",
    "\n",
    "### **torch.optim is a module in PyTorch that provides a variety of optimization algorithms used to update the parameters of your model during training.**\n",
    "\n",
    "### **It includes common optimizers like Stochastic Gradient Descent (SGD), Adam, RMSprop, and more.**\n",
    "\n",
    "### **It handles weight updates efficiently, including additional features like learning rate scheduling and weight decay (regularization).**\n",
    "\n",
    "### **The model.parameter() method in PyTorch retrieves an iterator over all the trainable parameters (weights and biases) in a model. The optimizer uses these parameters to compute gradients and update them during training.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1519b497-c730-453e-8eea-b7d6a6e3a81a",
   "metadata": {},
   "source": [
    "## Improves Code -- Existing Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42341744-c3a2-4313-b8b0-5655b4a495e9",
   "metadata": {},
   "source": [
    "## create model\n",
    "\n",
    "model = MyModel(X_train_tensor)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## forward pass\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "    ## loss function\n",
    "    loss = model.loss_function(y_pred,y_train_tensor)\n",
    "    ## backward pass\n",
    "    loss.backward()\n",
    "    ## parameter update \n",
    "    with torch.no_grad():\n",
    "        model.weights -= learning_rate * model.weights.grad\n",
    "        model.bias -= learning_rate * model.bias.grad\n",
    "\n",
    "    ## zero gradient \n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d4d2050-3238-4889-b497-1824a78e4b27",
   "metadata": {},
   "source": [
    "## create model\n",
    "\n",
    "model = MyModel(X_train_tensor)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## forward pass\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "    ## loss function\n",
    "    loss = model.loss_function(y_pred,y_train_tensor)\n",
    "    ## backward pass\n",
    "    loss.backward()\n",
    "    ## parameter update \n",
    "    with torch.no_grad():\n",
    "        model.weights -= learning_rate * model.weights.grad\n",
    "        model.bias -= learning_rate * model.bias.grad\n",
    "\n",
    "    ## zero gradient \n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7a48c-2f2b-403b-a77e-f8b055af584a",
   "metadata": {},
   "source": [
    "## Improvements -- Replace with PyTorch nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2246bc6-c0c5-4830-af3b-0bbf6aeed8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6869089603424072\n",
      "Epoch: 2, Loss: 0.667261004447937\n",
      "Epoch: 3, Loss: 0.6488147377967834\n",
      "Epoch: 4, Loss: 0.6306271553039551\n",
      "Epoch: 5, Loss: 0.6134985089302063\n",
      "Epoch: 6, Loss: 0.5966671705245972\n",
      "Epoch: 7, Loss: 0.5805893540382385\n",
      "Epoch: 8, Loss: 0.565207302570343\n",
      "Epoch: 9, Loss: 0.5506453514099121\n",
      "Epoch: 10, Loss: 0.5369421243667603\n",
      "Epoch: 11, Loss: 0.523980438709259\n",
      "Epoch: 12, Loss: 0.5119075775146484\n",
      "Epoch: 13, Loss: 0.5006181597709656\n",
      "Epoch: 14, Loss: 0.4901822507381439\n",
      "Epoch: 15, Loss: 0.4805448055267334\n",
      "Epoch: 16, Loss: 0.47151970863342285\n",
      "Epoch: 17, Loss: 0.4631381332874298\n",
      "Epoch: 18, Loss: 0.45528191328048706\n",
      "Epoch: 19, Loss: 0.44784975051879883\n",
      "Epoch: 20, Loss: 0.4408469796180725\n",
      "Epoch: 21, Loss: 0.4342362582683563\n",
      "Epoch: 22, Loss: 0.42795196175575256\n",
      "Epoch: 23, Loss: 0.42196890711784363\n",
      "Epoch: 24, Loss: 0.41629114747047424\n",
      "Epoch: 25, Loss: 0.4109046161174774\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            ## input layer \n",
    "            nn.Linear(num_features,3),\n",
    "            #applied relu\n",
    "            nn.ReLU(),\n",
    "            # output layer\n",
    "            nn.Linear(3,1),\n",
    "            ## applied sigmoid\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self,features):\n",
    "        out = self.network(features)\n",
    "        return out\n",
    "\n",
    "# Make sure both tensors are of type float32\n",
    "X_train_tensor = X_train_tensor.float()\n",
    "y_train_tensor = y_train_tensor.float()\n",
    "X_test_tensor = X_test_tensor.float()\n",
    "y_test_tensor = y_test_tensor.float()\n",
    "\n",
    "\n",
    "model = MyModel(X_train_tensor.shape[1])\n",
    "\n",
    "## define optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "## define loop \n",
    "for epoch in range(25):\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss_function = nn.BCELoss()\n",
    "    loss = loss_function(y_pred,y_train_tensor.view(-1,1))\n",
    "\n",
    "    ## clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    ## parameter update\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615168c-6cc2-458b-8bf0-bbb62786d54b",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "995ad301-eecf-4566-897d-787316b1f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.6578947305679321\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred>0.9).float()\n",
    "    accuracy = (y_pred==y_test_tensor).float().mean()\n",
    "    print(f'Accuarcy: {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "126bd175-984d-48a5-8120-dea441f7f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\rajsi\\anaconda3\\lib\\site-packages\\mask_rcnn-2.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590efa5-a8c8-40d9-9dd8-2016408b3f11",
   "metadata": {},
   "source": [
    "## Show Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c2fdef2-fae0-4b77-b31c-915095bef825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [455, 1]                  --\n",
       "├─Sequential: 1-1                        [455, 1]                  --\n",
       "│    └─Linear: 2-1                       [455, 3]                  93\n",
       "│    └─ReLU: 2-2                         [455, 3]                  --\n",
       "│    └─Linear: 2-3                       [455, 1]                  4\n",
       "│    └─Sigmoid: 2-4                      [455, 1]                  --\n",
       "==========================================================================================\n",
       "Total params: 97\n",
       "Trainable params: 97\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.07\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model,input_size=(X_train_tensor.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
